{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain-core langchain-cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "runnable = RunnableLambda(lambda x: x+1)\n",
    "response = runnable.invoke(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from langchain_core.runnables import Runnable, RunnableConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment_x_by_one(x: int) -> int:\n",
    "    return x+1\n",
    "\n",
    "def fake_llm(x: int) -> str:\n",
    "    return f\"Result = {x}\"\n",
    "\n",
    "class MyFirstChain(Runnable[int,str]):\n",
    "    def invoke(self, input:int, config: Optional[RunnableConfig]=None) -> str:\n",
    "        increment = increment_x_by_one(input)\n",
    "        return fake_llm(increment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = MyFirstChain()\n",
    "response = runnable.invoke(1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    RunnableLambda(increment_x_by_one\n",
    "                   ) | RunnableLambda(fake_llm)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke(1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableSequence\n",
    "\n",
    "a = (RunnableLambda(increment_x_by_one) | RunnableLambda(fake_llm)) \n",
    "b = (RunnableSequence(RunnableLambda(increment_x_by_one) | RunnableLambda(fake_llm)))\n",
    "\n",
    "print(a==b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "chain = RunnableParallel(\n",
    "    step1 = (increment_x_by_one | RunnableLambda(fake_llm)), step2 = fake_llm)\n",
    "\n",
    "chain.invoke(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1 = increment_x_by_one | chain\n",
    "chain1.invoke(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel \n",
    "chain2 = (RunnableLambda(increment_x_by_one)\n",
    "  | {\"step1\": increment_x_by_one | RunnableLambda(fake_llm),\n",
    "     \"step2\": fake_llm}\n",
    ")\n",
    "print(chain1 == chain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "chain = (\n",
    "    itemgetter(\"x\")\n",
    "    | RunnableLambda(increment_x_by_one)\n",
    "    | fake_llm\n",
    ")\n",
    "chain.invoke({\"x\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain_rps = RunnableParallel(\n",
    "    origin=RunnablePassthrough(),\n",
    "    output=increment_x_by_one\n",
    ")\n",
    "chain_rps.invoke(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-google-vertexai langchain-google-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering-OXoZ3f-b-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
